{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import library\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.365263Z","iopub.execute_input":"2022-05-19T07:37:29.365808Z","iopub.status.idle":"2022-05-19T07:37:29.371057Z","shell.execute_reply.started":"2022-05-19T07:37:29.365767Z","shell.execute_reply":"2022-05-19T07:37:29.370416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)    \n\ntrain_dataset = image_generator.flow_from_directory(batch_size=10,\n                                                 directory='../input/face-recognize',\n                                                 shuffle=True,\n                                                 target_size=(150, 150), \n                                                 subset=\"training\",\n                                                 class_mode='categorical')\n\nvalidation_dataset = image_generator.flow_from_directory(batch_size=10,\n                                                 directory='../input/face-recognize',\n                                                 shuffle=True,\n                                                 target_size=(150, 150), \n                                                 subset=\"validation\",\n                                                 class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.376396Z","iopub.execute_input":"2022-05-19T07:37:29.377149Z","iopub.status.idle":"2022-05-19T07:37:29.587576Z","shell.execute_reply.started":"2022-05-19T07:37:29.377113Z","shell.execute_reply":"2022-05-19T07:37:29.586839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.classes\ntrain_dataset.class_indices","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.589391Z","iopub.execute_input":"2022-05-19T07:37:29.58988Z","iopub.status.idle":"2022-05-19T07:37:29.595248Z","shell.execute_reply.started":"2022-05-19T07:37:29.589842Z","shell.execute_reply":"2022-05-19T07:37:29.594593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np  #\nimport pandas as pd # xu ly mang\nimport seaborn as sns # do thi\nimport matplotlib.pyplot as plt # ve do hoa\nfrom sklearn.preprocessing import StandardScaler  # xu ly du lieu , du lieu k dong deu\nfrom sklearn.model_selection import train_test_split # chia du lieu \nfrom keras.layers import Dense,Activation,Dropout,BatchNormalization,LSTM #  :batch... : chuan cua ANN\nfrom keras.models import Sequential #\nfrom tensorflow.keras.utils import to_categorical #  de dam bao do hcinh xac cao \nfrom keras import callbacks #\nfrom sklearn .metrics import  precision_score,recall_score, confusion_matrix, classification_report, accuracy_score,f1_score # thu vien cho do luong\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.596546Z","iopub.execute_input":"2022-05-19T07:37:29.596922Z","iopub.status.idle":"2022-05-19T07:37:29.605162Z","shell.execute_reply.started":"2022-05-19T07:37:29.596888Z","shell.execute_reply":"2022-05-19T07:37:29.60446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Tạo mô hinh\nfrom keras.layers import Conv2D, MaxPooling2D\nmodel = Sequential()\nmodel.add(Conv2D(32,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(150,150,3))) # 32 lần tích chập\nmodel.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(150,150,3))) # 64 lần tích chập\nmodel.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(150,150,3))) # 128 lần tích chập\nmodel.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.607255Z","iopub.execute_input":"2022-05-19T07:37:29.607498Z","iopub.status.idle":"2022-05-19T07:37:29.669672Z","shell.execute_reply.started":"2022-05-19T07:37:29.607467Z","shell.execute_reply":"2022-05-19T07:37:29.669002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Activation, Flatten\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.671046Z","iopub.execute_input":"2022-05-19T07:37:29.671424Z","iopub.status.idle":"2022-05-19T07:37:29.704015Z","shell.execute_reply.started":"2022-05-19T07:37:29.67139Z","shell.execute_reply":"2022-05-19T07:37:29.703356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\nopt = SGD(learning_rate = 0.001, momentum = 0.9)\nmodel .compile(optimizer = opt, loss ='categorical_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.705271Z","iopub.execute_input":"2022-05-19T07:37:29.705499Z","iopub.status.idle":"2022-05-19T07:37:29.715998Z","shell.execute_reply.started":"2022-05-19T07:37:29.705468Z","shell.execute_reply":"2022-05-19T07:37:29.715308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_dataset,batch_size=32,epochs=10,verbose=1,validation_data=validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:29.717305Z","iopub.execute_input":"2022-05-19T07:37:29.717588Z","iopub.status.idle":"2022-05-19T07:37:30.930142Z","shell.execute_reply.started":"2022-05-19T07:37:29.717531Z","shell.execute_reply":"2022-05-19T07:37:30.92903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train','Validation'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:30.931282Z","iopub.status.idle":"2022-05-19T07:37:30.932197Z","shell.execute_reply.started":"2022-05-19T07:37:30.931949Z","shell.execute_reply":"2022-05-19T07:37:30.931985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(validation_dataset,verbose=0)\nprint('Sai số : ',score[0])\nprint('Độ chính xác ',score[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:30.935082Z","iopub.status.idle":"2022-05-19T07:37:30.935994Z","shell.execute_reply.started":"2022-05-19T07:37:30.935758Z","shell.execute_reply":"2022-05-19T07:37:30.935784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.utils import load_img, img_to_array\nfilename = \"../input/conmeo-test/conmeo.jpg\"\n\nimg = load_img(filename,target_size=(150,150))\nplt.imshow(img)\nplt.show\nimg = img_to_array(img)\nimg  = img.reshape(1,150,150,3)\nimg = img.astype('float32')\nimg = img/255\ntest = np.argmax(model.predict(img),axis =1)\nif(test ==0):\n    print(\"Ba Huy\")\nif(test==1):\n    print(\"Con Meo\")\nif(test ==2):\n    print(\"Con Cho\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T07:37:30.937521Z","iopub.status.idle":"2022-05-19T07:37:30.937952Z","shell.execute_reply.started":"2022-05-19T07:37:30.937723Z","shell.execute_reply":"2022-05-19T07:37:30.937746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}